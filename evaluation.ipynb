{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "from time import time\n",
    "\n",
    "from src.simple_lookup import simple_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open('notebooks/science-counts.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['introduce',\n",
       " 'present',\n",
       " 'develop',\n",
       " 'devise',\n",
       " 'proposes',\n",
       " 'describe',\n",
       " 'adopt',\n",
       " 'employ',\n",
       " 'introduces',\n",
       " 'presents']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_lookup('propose', 'VERB', embkey=\"arxiv_abs\")['words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num nouns: 36241\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['dataset',\n",
       " 'analysis',\n",
       " 'optimization',\n",
       " 'time',\n",
       " 'systems',\n",
       " 'system',\n",
       " 'function',\n",
       " 'classification',\n",
       " 'problem',\n",
       " 'accuracy',\n",
       " 'curves',\n",
       " 'neighbors',\n",
       " 'fraction',\n",
       " 'decades',\n",
       " 'implications',\n",
       " 'setup',\n",
       " 'manifold',\n",
       " 'abstraction',\n",
       " 'pedestrian',\n",
       " 'messages']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns = data['NOUN']\n",
    "nouns_sorted = sorted(nouns, key=nouns.__getitem__, reverse=True)\n",
    "num = len(nouns.keys())\n",
    "print('num nouns:', num)\n",
    "top50 = nouns_sorted[:50]\n",
    "mid50 = nouns_sorted[1000:1050]\n",
    "queries = random.sample(top50, 10) + random.sample(mid50, 10)\n",
    "queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt at specificity/generality measure just with frequency info.\n",
    "Doesn't work that well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specificy: +1 more specific than query, -1 less specific, 0 about the same\n",
      "query\tresponse\tspecificy\tq count\tr count\n",
      "dataset\tdatabase\t1\t6328\t1610\n",
      "dataset\tdatasets\t0\t6328\t6321\n",
      "dataset\timagenet\t1\t6328\t4\n",
      "dataset\ttreebank\t1\t6328\t37\n",
      "dataset\tlfw\t1\t6328\t1\n",
      "dataset\twall\t1\t6328\t61\n",
      "dataset\tdatabases\t1\t6328\t733\n",
      "dataset\tsuite\t1\t6328\t132\n",
      "dataset\tdigits\t1\t6328\t136\n",
      "dataset\tmnist\t1\t6328\t1\n",
      "analysis\tanalyses\t1\t8275\t377\n",
      "analysis\tinvestigation\t1\t8275\t331\n",
      "analysis\tjustification\t1\t8275\t131\n",
      "analysis\tcharacterization\t1\t8275\t428\n",
      "analysis\tunderstanding\t1\t8275\t1339\n",
      "analysis\tvisualization\t1\t8275\t402\n",
      "analysis\tinvestigations\t1\t8275\t100\n",
      "analysis\tstudies\t1\t8275\t1597\n",
      "analysis\toverview\t1\t8275\t316\n",
      "analysis\ttheory\t1\t8275\t3096\n",
      "optimization\toptimisation\t1\t5856\t320\n",
      "optimization\tminimization\t1\t5856\t1074\n",
      "optimization\tsolving\t1\t5856\t33\n",
      "optimization\trelaxation\t1\t5856\t414\n",
      "optimization\tnonconvex\t1\t5856\t175\n",
      "optimization\tsolver\t1\t5856\t429\n",
      "optimization\trelaxations\t1\t5856\t136\n",
      "optimization\tapproximation\t1\t5856\t2160\n",
      "optimization\tmultiobjective\t1\t5856\t26\n",
      "optimization\tmaximization\t1\t5856\t387\n",
      "time\ttimes\t1\t11643\t971\n",
      "time\truntime\t1\t11643\t390\n",
      "time\ttimestep\t1\t11643\t18\n",
      "time\trounds\t1\t11643\t82\n",
      "time\tstorage\t1\t11643\t413\n",
      "time\texpense\t1\t11643\t88\n",
      "time\tlatency\t1\t11643\t145\n",
      "time\tcost\t1\t11643\t2816\n",
      "time\tgenerations\t1\t11643\t79\n",
      "time\tcosts\t1\t11643\t517\n",
      "systems\ttechnologies\t1\t6467\t387\n",
      "systems\tcontrollers\t1\t6467\t132\n",
      "systems\tframeworks\t1\t6467\t410\n",
      "systems\tsystem\t0\t6467\t9415\n",
      "systems\tmethodologies\t1\t6467\t198\n",
      "systems\tpipelines\t1\t6467\t154\n",
      "systems\tplanners\t1\t6467\t122\n",
      "systems\ttools\t1\t6467\t1268\n",
      "systems\tplatforms\t1\t6467\t331\n",
      "systems\tinterfaces\t1\t6467\t162\n",
      "system\tsystems\t0\t9415\t6467\n",
      "system\tprotocol\t1\t9415\t245\n",
      "system\tengine\t1\t9415\t388\n",
      "system\tplatform\t1\t9415\t529\n",
      "system\tsimulator\t1\t9415\t187\n",
      "system\tprototype\t1\t9415\t318\n",
      "system\tmanager\t1\t9415\t35\n",
      "system\tcompiler\t1\t9415\t43\n",
      "system\ttoolkit\t1\t9415\t97\n",
      "system\tinterface\t1\t9415\t390\n",
      "function\tfunctions\t0\t6732\t4172\n",
      "function\tsurrogate\t1\t6732\t135\n",
      "function\toperator\t1\t6732\t862\n",
      "function\tregularizer\t1\t6732\t292\n",
      "function\tcrossentropy\t1\t6732\t2\n",
      "function\tformula\t1\t6732\t301\n",
      "function\tsmooth\t1\t6732\t3\n",
      "function\tpredictor\t1\t6732\t283\n",
      "function\tcumulative\t1\t6732\t3\n",
      "function\tmetric\t1\t6732\t819\n",
      "classification\tprediction\t1\t9467\t4178\n",
      "classification\ttagging\t1\t9467\t147\n",
      "classification\tsegmentation\t1\t9467\t4541\n",
      "classification\tlabeling\t1\t9467\t703\n",
      "classification\tmultilabel\t1\t9467\t65\n",
      "classification\tclassifiers\t1\t9467\t1920\n",
      "classification\tclassifier\t1\t9467\t2299\n",
      "classification\tclustering\t1\t9467\t1709\n",
      "classification\tdiscrimination\t1\t9467\t284\n",
      "classification\textraction\t1\t9467\t1754\n",
      "problem\tproblems\t0\t16990\t8559\n",
      "problem\tcombinatorial\t1\t16990\t7\n",
      "problem\tformulation\t1\t16990\t1229\n",
      "problem\tsetting\t1\t16990\t2053\n",
      "problem\tmultiobjective\t1\t16990\t26\n",
      "problem\tcase\t1\t16990\t3601\n",
      "problem\tconvex\t1\t16990\t2195\n",
      "problem\tsubproblems\t1\t16990\t114\n",
      "problem\trelaxation\t1\t16990\t414\n",
      "problem\tconstraint\t1\t16990\t1497\n",
      "accuracy\taccuracies\t1\t6964\t306\n",
      "accuracy\tperformance\t-1\t6964\t13778\n",
      "accuracy\tprecision\t1\t6964\t1155\n",
      "accuracy\tperplexity\t1\t6964\t118\n",
      "accuracy\trecall\t1\t6964\t420\n",
      "accuracy\tefficiency\t1\t6964\t2131\n",
      "accuracy\tquality\t0\t6964\t4054\n",
      "accuracy\tthroughput\t1\t6964\t156\n",
      "accuracy\tf1\t1\t6964\t7\n",
      "accuracy\terror\t0\t6964\t3774\n",
      "curves\tinvariants\t1\t299\t118\n",
      "curves\tsurfaces\t0\t299\t199\n",
      "curves\tspectra\t1\t299\t142\n",
      "curves\tcoefficients\t-1\t299\t662\n",
      "curves\tcurve\t0\t299\t407\n",
      "curves\tindices\t0\t299\t157\n",
      "curves\tpolynomials\t1\t299\t99\n",
      "curves\tderivatives\t0\t299\t187\n",
      "curves\tplanes\t1\t299\t87\n",
      "curves\tcovariances\t1\t299\t53\n",
      "neighbors\tneighbours\t1\t298\t36\n",
      "neighbors\tcentroid\t1\t298\t49\n",
      "neighbors\tparent\t1\t298\t79\n",
      "neighbors\tcoordinates\t0\t298\t196\n",
      "neighbors\tcolumns\t0\t298\t184\n",
      "neighbors\tcandidates\t0\t298\t411\n",
      "neighbors\teigenvectors\t1\t298\t148\n",
      "neighbors\tneighborhoods\t1\t298\t121\n",
      "neighbors\tseed\t1\t298\t128\n",
      "neighbors\tpaths\t0\t298\t429\n",
      "fraction\tamount\t-1\t296\t1379\n",
      "fraction\tnumber\t-1\t296\t8318\n",
      "fraction\thalf\t1\t296\t100\n",
      "fraction\tm\t0\t296\t194\n",
      "fraction\tn\t1\t296\t89\n",
      "fraction\tpercentage\t1\t296\t142\n",
      "fraction\tt\t0\t296\t232\n",
      "fraction\tepoch\t1\t296\t50\n",
      "fraction\tp\t1\t296\t133\n",
      "fraction\tk\t-1\t296\t570\n",
      "decades\tyears\t-1\t302\t1447\n",
      "decades\tdecade\t0\t302\t260\n",
      "decades\tpapers\t0\t302\t333\n",
      "decades\tcountries\t1\t302\t96\n",
      "decades\tpublications\t1\t302\t87\n",
      "decades\tmonths\t1\t302\t61\n",
      "decades\tinnovations\t1\t302\t84\n",
      "decades\tdays\t1\t302\t141\n",
      "decades\tresearches\t1\t302\t92\n",
      "decades\tbreakthroughs\t1\t302\t49\n",
      "implications\tconsequences\t0\t306\t198\n",
      "implications\tsignificance\t0\t306\t206\n",
      "implications\tfoundations\t1\t306\t99\n",
      "implications\timpact\t-1\t306\t827\n",
      "implications\tpotential\t-1\t306\t964\n",
      "implications\tjustification\t1\t306\t131\n",
      "implications\tlimitations\t-1\t306\t753\n",
      "implications\tconsiderations\t1\t306\t123\n",
      "implications\tscope\t0\t306\t202\n",
      "implications\tmotivation\t0\t306\t240\n",
      "setup\tscenario\t-1\t291\t642\n",
      "setup\tprotocol\t0\t291\t245\n",
      "setup\tsimulator\t0\t291\t187\n",
      "setup\tenvironment\t-1\t291\t1748\n",
      "setup\tsituation\t0\t291\t430\n",
      "setup\tgame\t-1\t291\t1151\n",
      "setup\tparadigm\t-1\t291\t714\n",
      "setup\tscenarios\t-1\t291\t1172\n",
      "setup\tenvironments\t-1\t291\t1109\n",
      "setup\tpipeline\t-1\t291\t654\n",
      "manifold\tmanifolds\t0\t295\t295\n",
      "manifold\tsubspace\t-1\t295\t503\n",
      "manifold\tgeometry\t-1\t295\t747\n",
      "manifold\tsubspaces\t0\t295\t437\n",
      "manifold\ttangent\t1\t295\t39\n",
      "manifold\tprojection\t-1\t295\t800\n",
      "manifold\tmatrices\t-1\t295\t1180\n",
      "manifold\ttensors\t0\t295\t187\n",
      "manifold\tspace\t-1\t295\t6016\n",
      "manifold\tgeometric\t1\t295\t3\n",
      "abstraction\thierarchy\t-1\t294\t492\n",
      "abstraction\tabstractions\t1\t294\t130\n",
      "abstraction\tabstract\t1\t294\t28\n",
      "abstraction\tformalism\t0\t294\t315\n",
      "abstraction\thighlevel\t1\t294\t3\n",
      "abstraction\tsyntax\t0\t294\t271\n",
      "abstraction\trepresentation\t-1\t294\t5660\n",
      "abstraction\tsemantics\t-1\t294\t1516\n",
      "abstraction\tencoder\t-1\t294\t837\n",
      "abstraction\tencoding\t-1\t294\t589\n",
      "pedestrian\tkeypoint\t1\t297\t129\n",
      "pedestrian\tanomaly\t0\t297\t337\n",
      "pedestrian\tlandmark\t0\t297\t288\n",
      "pedestrian\tchangepoint\t1\t297\t8\n",
      "pedestrian\tsarcasm\t1\t297\t64\n",
      "pedestrian\tstance\t1\t297\t66\n",
      "pedestrian\temotion\t0\t297\t349\n",
      "pedestrian\tplagiarism\t1\t297\t41\n",
      "pedestrian\tabnormality\t1\t297\t46\n",
      "pedestrian\tparaphrase\t1\t297\t73\n",
      "messages\tposts\t0\t295\t158\n",
      "messages\tstories\t1\t295\t112\n",
      "messages\ttweets\t0\t295\t359\n",
      "messages\tsites\t0\t295\t172\n",
      "messages\twebsites\t1\t295\t110\n",
      "messages\tcomments\t1\t295\t130\n",
      "messages\tpages\t0\t295\t170\n",
      "messages\tedits\t1\t295\t41\n",
      "messages\trecords\t0\t295\t269\n",
      "messages\tmetadata\t0\t295\t149\n"
     ]
    }
   ],
   "source": [
    "print('specificy: +1 more specific than query, -1 less specific, 0 about the same')\n",
    "print('{}\\t{}\\t{}\\t{}\\t{}'.format('query', 'response', 'specificy', 'q count', 'r count'))\n",
    "for q in queries:\n",
    "    responses = simple_lookup(q, 'NOUN', embkey=\"arxiv_abs\")['words']\n",
    "    for r in responses:\n",
    "        d = nouns[q] - nouns[r]\n",
    "        p = nouns[q]*.5\n",
    "        s = 0\n",
    "        if d > p:\n",
    "            s = 1\n",
    "        if d < -p:\n",
    "            s = -1\n",
    "        print('{}\\t{}\\t{}\\t{}\\t{}'.format(q, r, s, nouns[q], nouns[r]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'We propose an architecture for VQA which utilizes recurrent layers to generate visual and textual attention. The memory characteristic of the proposed recurrent attention units offers a rich joint embedding of visual and textual features and enables the model to reason relations between several parts of the image and question. Our single model outperforms the first place winner on the VQA 1.0 dataset, performs within margin to the current state-of-the-art ensemble model. We also experiment with replacing attention mechanisms in other state-of-the-art models with our implementation and show increased accuracy. In both cases, our recurrent attention mechanism improves performance in tasks requiring sequential or relational reasoning on the VQA dataset.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('dat/corpora/arxiv_abs/summaries.txt', 'r') as fle:\n",
    "    abstracts = fle.read()\n",
    "\n",
    "abstracts_ = abstracts.split('\\n')\n",
    "print(len(abstracts_))\n",
    "abstracts_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . "
     ]
    }
   ],
   "source": [
    "contexts = {}\n",
    "count = 0\n",
    "for a in abstracts_:\n",
    "    count += 1\n",
    "    if count % 1000 == 0:\n",
    "        print('.', end=' ')\n",
    "    clean = re.sub('[,.\\?]', '', a)\n",
    "    words = clean.lower().split(' ')\n",
    "    for i, w in enumerate(words):\n",
    "        if w not in contexts:\n",
    "            contexts[w] = []\n",
    "        for j in range(max(0, i-2), min(len(words), i+2)):\n",
    "            if words[j] not in contexts[w]:\n",
    "                contexts[w].append(words[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3353\n",
      "204\n"
     ]
    }
   ],
   "source": [
    "print(len(contexts['dataset']))\n",
    "print(len(contexts['metadata']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specificy: +1 more specific than query, -1 less specific, 0 about the same\n",
      "query               response            specificy q count   r count   \n",
      "--------\n",
      "network             net                 1         4605      416       \n",
      "network             networks            0         4605      3237      \n",
      "network             nets                1         4605      303       \n",
      "network             enquirer            1         4605      15        \n",
      "network             cnn                 1         4605      1215      \n",
      "network             architecture        1         4605      1744      \n",
      "network             convnet             1         4605      223       \n",
      "network             decoder             1         4605      400       \n",
      "network             controller          1         4605      321       \n",
      "network             autoencoder         1         4605      357       \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('specificy: +1 more specific than query, -1 less specific, 0 about the same')\n",
    "print('{:<20}{:<20}{:<10}{:<10}{:<10}'.format('query', 'response', 'specificy', 'q count', 'r count'))\n",
    "print('--------')\n",
    "for q in ['network']:\n",
    "    responses = simple_lookup(q, 'NOUN', embkey=\"arxiv_abs\")['words']\n",
    "    for r in responses:\n",
    "        d = len(contexts[q]) - len(contexts[r])\n",
    "        p = len(contexts[q])*.5\n",
    "        s = 0\n",
    "        if d > p:\n",
    "            s = 1\n",
    "        if d < -p:\n",
    "            s = -1\n",
    "        print('{:<20}{:<20}{:<10}{:<10}{:<10}'.format(q, r, s, len(contexts[q]), len(contexts[r])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7755775577557755 2.8613385556052915\n",
      "3.5181518151815183 2.86877474392947\n",
      "2.514851485148515 1.901608810205782\n"
     ]
    }
   ],
   "source": [
    "nouns = data['NOUN']\n",
    "nouns_sorted = sorted(nouns, key=nouns.__getitem__, reverse=True)\n",
    "num = len(nouns.keys())\n",
    "top50 = nouns_sorted[:50]\n",
    "mid50 = nouns_sorted[1000:1050]\n",
    "manyqueries = random.sample(nouns_sorted, 1000)\n",
    "\n",
    "specific = []\n",
    "general = []\n",
    "neither = []\n",
    "for q in manyqueries:\n",
    "    try:\n",
    "        contexts[q]\n",
    "        responses = simple_lookup(q, 'NOUN', embkey=\"arxiv_abs\")['words']\n",
    "        for r in responses:\n",
    "            contexts[r]\n",
    "    except:\n",
    "        continue\n",
    "    s = 0\n",
    "    g = 0\n",
    "    n = 0\n",
    "    for r in responses:\n",
    "        d = len(contexts[q]) - len(contexts[r])\n",
    "        p = len(contexts[q])*.25\n",
    "        if d > p:\n",
    "            s += 1\n",
    "        elif d < -p:\n",
    "            g += 1\n",
    "        else:\n",
    "            n += 1\n",
    "    specific.append(s)\n",
    "    general.append(g)\n",
    "    neither.append(n)\n",
    "\n",
    "for array in [specific, general, neither]:\n",
    "    print(np.mean(array), np.std(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
